---
title: “统计学笔记”
author: ''
date: '2022-05-22'
slug: statistic 
categories: []
tags: []
---
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>


# 描述性统计学探索数据
图形描述
数字描述 数据集中的描述： 均值与中位数，数据对称时均值与中位数相等，均值向数据分布（右偏或
左偏）偏离。
数据分散的描述：interquartile range = erd quartile - 1st quartile
标准差是用于描述数据分散的常用数值。

均值和标准差都对少部分很大或很小的值很敏感，可以考虑使用中位数和interquartile range



# 数据产生，抽样
几个概念
总体（population):entire group we want information
参数（parameter)：quantity about the population we are 
interested in.

样本（sample): part of population from which we collect information
统计量（estimate，statistic）：the quantity we are interested in as 
measured in the sample
关键：即使一个很小的样本也能产生一个于总体参数相近的估计。

**正确的抽样**：bias(systematic error)
selection bias： a sample of convenience make it more likely
to sample certain subjects than others
non-response bias: less likely to answer a question at a
special situation
voluntary response bias: websites that post reviews of businenss
are more likely to get response from customer who had 
very bad or very good experiences.

**抽样方法**：
不放回的简单随机抽样（a simple random sampling)

分层的随机抽样(a stratified random sample):相似的为一层，然后再
后在每一层进行一个简单的随机抽样，然后把这些样本组合起来。

**Bias and chance error**:
chance error9(sampling error): 随机抽样，估计和总体的偏差，每一次的抽样有不
同的 chance error.
$$ 
estimate = parameter + bias(systematic error) + chance 
error(sampling error) 
$$

增大样本可以减少chance error，并且我们可以计算chance error具体有多大，
但是增大样本只是让bias在一个更大的规模上重复，并且我们不能知道
bias的大小。


**因果分析与关联分析**
observation study: 测量一个感兴趣的事的结果，用于观察关联关系。

association is not causation, there may be confounding factors

causation experiment(randomized controlled experiments):
1:subjects are assigned into treatment and control groups
at random.
2: subjects in controlled group get a placebo to ensure 
both groups equally affected by the placebo effect: the d
idea of being treated may have an effect by itself
3:double-blind

![安慰剂效应]（the wired power of placebo effect, explained '
by Brian Resnick)


# 概率
standard definition: proportion of times this event occurs
in many repetitions
subjective probability: not based on experiments, different
people assign different subjective probabilities to the 
same event.

**four basic rules**
complement rule: P(A does not occur) = 1 - P(A)
Rules for equally likely outcomes: P(A) = $ \frac{
 number of outcomes in A}{n}$
Addition rule: A and B are mutually exclusive(don't occure ate 
the same time), then:
$ P(A or B) = P(A) + P(B)
multiplication rule:A and B are independent(one occures
doesn't change the probability that the other occurs)
P(A and B) = P(A)(B)

**条件概率（conditional probability**
$ P(B|A) = \frac{P(A and B)}{P(A)} $
general multiplication rule: P(A and B) = P(A)P(B|A)
special case where A and B are independent: 
P(A and B) = P(A)P(B)

**Bayes's rule**
**Bayesian analysis**

**False positives case**
**warner's randomized response model**

# 正态分布与二项分布
Normal curve: bell-shaped
empirical rule
about 2/3(68%) fall within one sd of the mean 
about 95% fall within 2 sd of the mean
about  99.7 fall within 3 sd of the mean

standardize data:
 $ z = \frac{height - \bar{x}}{s}$
z meas how many sd the height away from the mean. no 
unites.

Normal approximation: finding areas under teh normal 
curve.(we can look up area to the left of a given value)
the empirical rule is a special case of normal 
approximation.
computing percentiles for normal data: 30% data for
normal curve, the height is z sd away from mean.

**binomial probability**
$$
\frac{X(success count) - np}{\sqrt{np(1 - p)}} \sim
N(0,1)
$$

简单随机抽样是不放回的抽样，不是二项分布设定，因为每取出一个
概率P就，改变了；但是如果总体size远大于样本size，那么
放回抽样和不放回抽样就是大致一致的，服从于二项分布，
服从于正态曲线。

# 样本分布和中心极限定理
expected value of the sample average , E( $\bar{x}_N $) is the population average.
standard error: statistic's sd, tells us roughly how
far off the statistic will be from it expected value.

square root law:
$ SE(\bar{x}_n) = \frac{\sigma}{\sqrt{n}} $
1.more lager sample size n, more smaller SE, it can
be used to determine sample size to get desired accuarcy
2. SE don't depend on the size of the population
,only on the size of the sample.

**expected value and se for sum**
$ E(S_n) = n\mu       SE(S_n) = \sqrt{n}\sigma $

**expected value and se for percentages**
framework for counting and classifying:
$$
E(percentage of 1s) = 1\mu100%  SE(percentage of 1s) =
 \frac{\sigma}{\sqrt{n}} 100%
$$

**expected value and se when simulating**
a random variable X that is simulated has K possible
outcomes ,
$ \mu = \sum_{i=1}^k x_i P(X = x_i),  \sigma^2 = 
\sum{i=1}^k (x_i - \mu)^2 P(X = x_i) $


three histograms:
probability histogram for producing the data
the histogram of 100 observed tosses
the probability of the statistic


law of large numbers:
when sample size is large enough, the $\bar{x_N}$
will be likely close to $\mu$
applied for averages and percentages,but not for sums
for sampling with replacement from a population or 
for simulating data from a probability histogram.

more advanced large number laws: the empirical histaogram 
will be close to probability to histogram producing the data.

**central limit theorem**
what is CLT?
the sample sum statistic(averages and percentages are sums in disguise) distribution is normal distribution

应用条件：放回抽样，或者每次都从同一个概率分布函数抽样（其实不同的也可以？）
sample size is large enough(if no strong skewness, n > 15 is 
sufficient)

# 线性回归
scatter plot three element: direction(slope up or down),
form(points cluster around a line or other), strength(how close
the points follow the form)

how to quantify the strength?
if it is liner former, the correlation coefficient r is a 
good choice. standardized x*y ,not affected by the scale of 
either variable. its sign gives the direction and its absolute
value gives the strength. 
note: r is only useful for measuring linear association.and
correlation does not mean causation

summary of pair date: $\bar{x}$, $s_x$, $\bar{y}$, $s_y$, $r$

how to get the regression line?
to minimize the MSE(mean squared error), the method of least
squares gives the analytic answer: $b = r\frac{s_y}{s_x}$ and
$a = \bar{y} - b\bar{x}$. this line y = a + bx is called 
the regression line.

Another interpretation of the regression line: if computes 
the average value of y when the first coordinate is near x
note: the average often times is the best estimate when no 
extra information is provided.

向均值回归？regression effect?回归效应
因为1 $\bar{x}$ 的预测值是 $\bar{y}$, 2. $b = r\frac{s_y}{s_x}$
也就是说当x 偏离 $\bar{x}$ 一个sd是， y只向 $\bar{y}$ 偏离 r*sd 个单位，也就是y is fewer sd away from $\bar{y} than x is from $\bar{x}$

i.e. football shaped scatter, exam scores. my be
caused by regression fallacy

note: x to y and y to x are two different regression 
line, cannot predict each other.

回归中的正态估计？
在回归线（football shape scatter)中的某一点x处，y服从于正态分布
即： $\frac{Y - y(predict)|x}{\sqrt{1 - r^2}s_y}$


如何检查回归使用是否正确？
residual plot. 残差就真实值与预测值的差. it should be a 
unstructured horizontal band.
curved plot: not liner;but the data can be $\sqrt{}$
or log transformation to liner to analyze.

scatter arises: heteroscedastic(may produce homoscedastic by y 
variable transformation, and it may result in a non-liner scatter
, which require a second transformation in of x to fix)

离群值 outliers
离x 均值很远的x可能会对回归线的构建有很大的影响（influential point_
,会使得回归线向它偏离，无法用残差图检验。


一些问题：
预测y时，x应该在其范围之中，超出x的取值范围以后可能就不是线性关系
对总结数据注意，比如平均值，它们的变化更小，相关性？
R^2,可以被回归线解释的部分，1 - r^2就是不能解释的，就是残差。

# confidence interval 
SE gives the chance error, confidence interval give a more
precise statement.
已知一个样本统计量的分布，那么每一次的抽样我们可以说有95%几率该样本的统计量大小不会偏离该总体参数的2个SE(如果该统计量服从于正态分布)，也就是可以说每一次抽样得到到统计量，我们都有95%的把握说总体参数不会偏离超过2SE于该统计量。每一次的抽样都可以得到一个置信区间。
注意：置信区间随着每一次抽样变化而变化，但是总体参数是一个固定的值。
  

confidence  = estimate +/- zSE(if statistic ~ normal distribution)

总体反差未知？
bootstrap：用样本方差代替得到一个估计置信区间。

其他：置信区间的大小由zSE决定，称作margin of error,因为
$SE = \frac{\sigma}{\sqrt{n}}， 所以可以通过增大样本size减少区间。 同样也可减少z减少区间，比如80%区间。
百分数的 95%置信区间： estimated percentage +/- $1\ \sqrt{n}$
因为 $\sigma = \sqrt{p(1 - p)} < 1/2$

# testing hypothesis
假设检验的逻辑？
设定零假设，备择假设，收集数据并评估该数据是否满足零假设从而接受
零假设或拒绝，零假设一般是什么都没有发生，所以我们想要拒绝它，导致假设检验的逻辑不是很直接。

检验统计量？test statistic
a test statistic measures how far away the data are from 
what we would expect if H0 is true.
i.e z-statistic:
$$ 
z = \frac{observed - expected}{SE}
$$
观测值是一个用于评估H0的统计量，expected and SE are the 
expected value and SE of the this statistic , computed under
the assumption H0 is true.

p value is the probability of getting a value of z as 
extreme or more extreme than the observed z, assuming HO is true

note:Ho 是否正确是 一个确定的事，p值只是给出了观察到如此极端值得概率大小，在HO为真的假设下。


















