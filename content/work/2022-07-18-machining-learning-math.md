---
title: machine learning math
date: '2022-07-18'
slug: machine-learning-math
---

## Liner algebra

向量，矩阵，符号记法，按需求理解。

vector addition rule, scalar multiplication
vector: size, angle, projection

size: square root of its sum of  component square  
projection: dot projection = dot projection  
dot product: 
- r vector's projection onto s vector 
- it's value equal r vector's projection size onto s vector
- equal |s||r|cos $\theta$ 
- scalar projection equal it's projection size divided by |s|
- projection vector equal it's scalar projection multiply s vector's united vector
- r's own dot product's square root equal its size.


矩阵乘法的两种理解
- 空间变化，所有的坐标都是基于一组特定的基，无论是原始向量，以及变换矩阵和变换后的向量。
- 坐标变化，a(a1, a2)基座标下的向量 r_a 变换到b(b1, b2)坐标下的向量，则将b1, b2由a(a1, a2表示)，形成基变化矩阵P，乘以 r_a, 将r_a变化为r_b。
